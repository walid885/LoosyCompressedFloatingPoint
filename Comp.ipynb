{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "277e264e-d9c4-4a8b-88a9-7db0ef12fe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133994/3281351146.py:111: DeprecationWarning: NumPy will stop allowing conversion of out-of-bound Python integers to integer arrays.  The conversion of -256 to uint64 will fail in the future.\n",
      "For the old behavior, usually:\n",
      "    np.array(value).astype(dtype)\n",
      "will give the desired result (the cast overflows).\n",
      "  mask = np.uint64(~((1 << num_bits) - 1))\n",
      "/tmp/ipykernel_133994/3281351146.py:111: DeprecationWarning: NumPy will stop allowing conversion of out-of-bound Python integers to integer arrays.  The conversion of -1024 to uint64 will fail in the future.\n",
      "For the old behavior, usually:\n",
      "    np.array(value).astype(dtype)\n",
      "will give the desired result (the cast overflows).\n",
      "  mask = np.uint64(~((1 << num_bits) - 1))\n",
      "/tmp/ipykernel_133994/3281351146.py:111: DeprecationWarning: NumPy will stop allowing conversion of out-of-bound Python integers to integer arrays.  The conversion of -4096 to uint64 will fail in the future.\n",
      "For the old behavior, usually:\n",
      "    np.array(value).astype(dtype)\n",
      "will give the desired result (the cast overflows).\n",
      "  mask = np.uint64(~((1 << num_bits) - 1))\n",
      "/tmp/ipykernel_133994/3281351146.py:111: DeprecationWarning: NumPy will stop allowing conversion of out-of-bound Python integers to integer arrays.  The conversion of -16384 to uint64 will fail in the future.\n",
      "For the old behavior, usually:\n",
      "    np.array(value).astype(dtype)\n",
      "will give the desired result (the cast overflows).\n",
      "  mask = np.uint64(~((1 << num_bits) - 1))\n",
      "/tmp/ipykernel_133994/3281351146.py:111: DeprecationWarning: NumPy will stop allowing conversion of out-of-bound Python integers to integer arrays.  The conversion of -65536 to uint64 will fail in the future.\n",
      "For the old behavior, usually:\n",
      "    np.array(value).astype(dtype)\n",
      "will give the desired result (the cast overflows).\n",
      "  mask = np.uint64(~((1 << num_bits) - 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive report generated at: enhanced_compression_analysis/comprehensive_analysis_report.txt\n",
      "\n",
      "Compression and Entropy Analysis Results:\n",
      "   Distribution  LSB_Zeroed  Original_Entropy_Fine  Compressed_Entropy_Fine  \\\n",
      "0       Uniform           8              13.287471                13.287471   \n",
      "1       Uniform          10              13.287471                13.287471   \n",
      "2       Uniform          12              13.287471                13.287471   \n",
      "3       Uniform          14              13.287471                13.287471   \n",
      "4       Uniform          16              13.287471                13.287471   \n",
      "5      Gaussian           8               8.383322                 8.383322   \n",
      "6      Gaussian          10               8.383322                 8.383322   \n",
      "7      Gaussian          12               8.383322                 8.383322   \n",
      "8      Gaussian          14               8.383322                 8.383322   \n",
      "9      Gaussian          16               8.383322                 8.383322   \n",
      "10  Exponential           8               7.501288                 7.501288   \n",
      "11  Exponential          10               7.501288                 7.501288   \n",
      "12  Exponential          12               7.501288                 7.501288   \n",
      "13  Exponential          14               7.501288                 7.501288   \n",
      "14  Exponential          16               7.501288                 7.501288   \n",
      "15       Skewed           8               2.743332                 2.743332   \n",
      "16       Skewed          10               2.743332                 2.743332   \n",
      "17       Skewed          12               2.743332                 2.743332   \n",
      "18       Skewed          14               2.743332                 2.743332   \n",
      "19       Skewed          16               2.743332                 2.743332   \n",
      "20      Bimodal           8              10.355655                10.355655   \n",
      "21      Bimodal          10              10.355655                10.355655   \n",
      "22      Bimodal          12              10.355655                10.355655   \n",
      "23      Bimodal          14              10.355655                10.355655   \n",
      "24      Bimodal          16              10.355655                10.355655   \n",
      "\n",
      "    Original_Entropy_Coarse  Compressed_Entropy_Coarse  KL_Divergence_Fine  \\\n",
      "0                  3.321917                   3.321917        0.000000e+00   \n",
      "1                  3.321917                   3.321917        0.000000e+00   \n",
      "2                  3.321917                   3.321917        0.000000e+00   \n",
      "3                  3.321917                   3.321917        0.000000e+00   \n",
      "4                  3.321917                   3.321917        0.000000e+00   \n",
      "5                  2.096588                   2.096588        0.000000e+00   \n",
      "6                  2.096588                   2.096588        0.000000e+00   \n",
      "7                  2.096588                   2.096588        0.000000e+00   \n",
      "8                  2.096588                   2.096588        0.000000e+00   \n",
      "9                  2.096588                   2.096588        0.000000e+00   \n",
      "10                 1.876770                   1.876770        1.728657e-11   \n",
      "11                 1.876770                   1.876770        1.728657e-11   \n",
      "12                 1.876770                   1.876770        1.728657e-11   \n",
      "13                 1.876770                   1.876770        1.728657e-11   \n",
      "14                 1.876770                   1.876770        1.728657e-11   \n",
      "15                 0.763550                   0.763550        1.415821e-12   \n",
      "16                 0.763550                   0.763550        1.415821e-12   \n",
      "17                 0.763550                   0.763550        1.415821e-12   \n",
      "18                 0.763550                   0.763550        1.415821e-12   \n",
      "19                 0.763550                   0.763550        1.415821e-12   \n",
      "20                 2.593648                   2.593648        0.000000e+00   \n",
      "21                 2.593648                   2.593648        0.000000e+00   \n",
      "22                 2.593648                   2.593648        0.000000e+00   \n",
      "23                 2.593648                   2.593648        0.000000e+00   \n",
      "24                 2.593648                   2.593648        0.000000e+00   \n",
      "\n",
      "    KL_Divergence_Coarse  Compression_Ratio           MSE  Max_Absolute_Error  \n",
      "0           0.000000e+00           1.163001  1.979730e-24        3.623768e-12  \n",
      "1           0.000000e+00           1.202123  3.186552e-23        1.453770e-11  \n",
      "2           0.000000e+00           1.251362  5.102759e-22        5.819345e-11  \n",
      "3           0.000000e+00           1.297513  8.164140e-21        2.328164e-10  \n",
      "4           0.000000e+00           1.366696  1.307161e-19        9.313084e-10  \n",
      "5           0.000000e+00           1.191379  1.573249e-24        3.623768e-12  \n",
      "6           0.000000e+00           1.232316  2.528599e-23        1.453770e-11  \n",
      "7           0.000000e+00           1.273371  4.059094e-22        5.819345e-11  \n",
      "8           0.000000e+00           1.320295  6.473030e-21        2.328164e-10  \n",
      "9           0.000000e+00           1.405437  1.038024e-19        9.313084e-10  \n",
      "10          9.823454e-13           1.145039  1.159258e-25        3.623768e-12  \n",
      "11          9.823454e-13           1.177908  1.868475e-24        1.453770e-11  \n",
      "12          9.823454e-13           1.235823  2.989461e-23        5.819345e-11  \n",
      "13          9.823454e-13           1.285534  4.786526e-22        2.326743e-10  \n",
      "14          9.823454e-13           1.344376  7.624281e-21        9.306405e-10  \n",
      "15          3.515486e-14           1.151155  4.263075e-27        5.570655e-12  \n",
      "16          3.515486e-14           1.186132  6.987693e-26        2.617639e-11  \n",
      "17          3.515486e-14           1.244843  1.095128e-24        9.288215e-11  \n",
      "18          3.515486e-14           1.291512  1.736210e-23        4.421281e-10  \n",
      "19          3.515486e-14           1.352466  2.832953e-22        1.186862e-09  \n",
      "20          0.000000e+00           1.226000  2.307427e-24        3.623768e-12  \n",
      "21          0.000000e+00           1.257250  3.712079e-23        1.453770e-11  \n",
      "22          0.000000e+00           1.297309  5.939924e-22        5.819345e-11  \n",
      "23          0.000000e+00           1.359519  9.507831e-21        2.328164e-10  \n",
      "24          0.000000e+00           1.458510  1.524545e-19        9.313084e-10  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import zlib\n",
    "import json\n",
    "\n",
    "class EnhancedFloatingPointCompressor:\n",
    "    def __init__(self, seed=42, sample_size=1_000_000):\n",
    "        \"\"\"\n",
    "        Initialize the compressor with specific parameters\n",
    "        \n",
    "        :param seed: Random seed for reproducibility\n",
    "        :param sample_size: Number of floating-point numbers to generate\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.sample_size = sample_size\n",
    "        \n",
    "        # Create output directory\n",
    "        self.output_dir = 'enhanced_compression_analysis'\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        # LSB (Least Significant Bits) to zero out\n",
    "        self.lsb_levels = [8, 10, 12, 14, 16]\n",
    "        \n",
    "        # Color palette for consistent visualization\n",
    "        self.color_palette = [\n",
    "            '#1f77b4',  # blue\n",
    "            '#ff7f0e',  # orange\n",
    "            '#2ca02c',  # green\n",
    "            '#d62728',  # red\n",
    "            '#9467bd',  # purple\n",
    "        ]\n",
    "\n",
    "    def generate_distributions(self):\n",
    "        \"\"\"\n",
    "        Generate floating-point numbers from different distributions\n",
    "        \n",
    "        :return: Dictionary of distributions\n",
    "        \"\"\"\n",
    "        # Ensure sample size is even for bimodal distribution\n",
    "        half_size = self.sample_size // 2\n",
    "        return {\n",
    "            'Uniform': np.random.uniform(0, 100, self.sample_size),\n",
    "            'Gaussian': np.random.normal(50, 15, self.sample_size),\n",
    "            'Exponential': np.random.exponential(10, self.sample_size),\n",
    "            'Skewed': np.random.lognormal(0, 1, self.sample_size),\n",
    "            'Bimodal': np.concatenate([\n",
    "                np.random.normal(20, 5, half_size), \n",
    "                np.random.normal(80, 5, half_size)\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def calculate_entropy(self, data, bins=100):\n",
    "        \"\"\"\n",
    "        Calculate Shannon entropy using histogram binning\n",
    "        \n",
    "        :param data: Input data array\n",
    "        :param bins: Number of bins for discretization\n",
    "        :return: Entropy value\n",
    "        \"\"\"\n",
    "        # Compute histogram with density normalization\n",
    "        hist, _ = np.histogram(data, bins=bins, density=True)\n",
    "        \n",
    "        # Remove zero probabilities to avoid log(0)\n",
    "        hist = hist[hist > 0]\n",
    "        \n",
    "        # Calculate entropy\n",
    "        return -np.sum(hist * np.log2(hist))\n",
    "\n",
    "    def calculate_kl_divergence(self, original_data, compressed_data, bins=100):\n",
    "        \"\"\"\n",
    "        Calculate Kullback-Leibler Divergence between original and compressed data\n",
    "        \n",
    "        :param original_data: Original data array\n",
    "        :param compressed_data: Compressed data array\n",
    "        :param bins: Number of bins for discretization\n",
    "        :return: KL Divergence value\n",
    "        \"\"\"\n",
    "        # Compute histograms\n",
    "        orig_hist, bin_edges = np.histogram(original_data, bins=bins, density=True)\n",
    "        comp_hist, _ = np.histogram(compressed_data, bins=bin_edges, density=True)\n",
    "        \n",
    "        # Remove zero probabilities\n",
    "        orig_hist = orig_hist[orig_hist > 0]\n",
    "        comp_hist = comp_hist[comp_hist > 0]\n",
    "        \n",
    "        # Ensure same length by truncating to the shorter array\n",
    "        min_len = min(len(orig_hist), len(comp_hist))\n",
    "        orig_hist = orig_hist[:min_len]\n",
    "        comp_hist = comp_hist[:min_len]\n",
    "        \n",
    "        # Calculate KL Divergence\n",
    "        return np.sum(orig_hist * np.log2(orig_hist / comp_hist))\n",
    "\n",
    "    def compress_data(self, data, num_bits):\n",
    "        \"\"\"\n",
    "        Compress data by zeroing out least significant bits\n",
    "        \n",
    "        :param data: Input array of floating-point numbers\n",
    "        :param num_bits: Number of least significant bits to zero out\n",
    "        :return: Compressed data and analysis metrics\n",
    "        \"\"\"\n",
    "        # Convert to 64-bit integer representation\n",
    "        int_data = data.view(np.uint64)\n",
    "        \n",
    "        # Create a mask to zero out least significant bits\n",
    "        mask = np.uint64(~((1 << num_bits) - 1))\n",
    "        \n",
    "        # Apply the mask\n",
    "        compressed_int = int_data & mask\n",
    "        \n",
    "        # Convert back to floating-point\n",
    "        compressed_data = compressed_int.view(np.float64)\n",
    "        \n",
    "        # Additional analysis\n",
    "        byte_data = compressed_data.tobytes()\n",
    "        compressed_bytes = zlib.compress(byte_data)\n",
    "        \n",
    "        return {\n",
    "            'original_data': data,\n",
    "            'compressed_data': compressed_data,\n",
    "            'original_entropy_fine': self.calculate_entropy(data, bins=200),\n",
    "            'original_entropy_coarse': self.calculate_entropy(data, bins=50),\n",
    "            'compressed_entropy_fine': self.calculate_entropy(compressed_data, bins=200),\n",
    "            'compressed_entropy_coarse': self.calculate_entropy(compressed_data, bins=50),\n",
    "            'kl_divergence_fine': self.calculate_kl_divergence(data, compressed_data, bins=200),\n",
    "            'kl_divergence_coarse': self.calculate_kl_divergence(data, compressed_data, bins=50),\n",
    "            'original_size': len(byte_data),\n",
    "            'compressed_size': len(compressed_bytes),\n",
    "            'compression_ratio': len(byte_data) / len(compressed_bytes),\n",
    "            'mse': np.mean((data - compressed_data)**2),\n",
    "            'max_abs_error': np.max(np.abs(data - compressed_data))\n",
    "        }\n",
    "\n",
    "    def analyze_compression(self):\n",
    "        \"\"\"\n",
    "        Perform comprehensive compression and entropy analysis\n",
    "        \"\"\"\n",
    "        # Generate distributions\n",
    "        distributions = self.generate_distributions()\n",
    "        \n",
    "        # Prepare results storage\n",
    "        all_results = []\n",
    "        \n",
    "        # Create a figure with multiple subplots\n",
    "        fig, axs = plt.subplots(len(distributions), 4, figsize=(24, 4*len(distributions)))\n",
    "        fig.suptitle('Comprehensive Compression and Entropy Analysis', fontsize=16)\n",
    "        \n",
    "        # Iterate through distributions\n",
    "        for row, (dist_name, original_data) in enumerate(distributions.items()):\n",
    "            # Prepare storage for results\n",
    "            compression_results = []\n",
    "            \n",
    "            # Analyze compression for different LSB levels\n",
    "            for lsb in self.lsb_levels:\n",
    "                # Compress data\n",
    "                result = self.compress_data(original_data, lsb)\n",
    "                \n",
    "                # Store detailed results\n",
    "                compression_result = {\n",
    "                    'Distribution': dist_name,\n",
    "                    'LSB_Zeroed': lsb,\n",
    "                    'Original_Entropy_Fine': result['original_entropy_fine'],\n",
    "                    'Compressed_Entropy_Fine': result['compressed_entropy_fine'],\n",
    "                    'Original_Entropy_Coarse': result['original_entropy_coarse'],\n",
    "                    'Compressed_Entropy_Coarse': result['compressed_entropy_coarse'],\n",
    "                    'KL_Divergence_Fine': result['kl_divergence_fine'],\n",
    "                    'KL_Divergence_Coarse': result['kl_divergence_coarse'],\n",
    "                    'Compression_Ratio': result['compression_ratio'],\n",
    "                    'MSE': result['mse'],\n",
    "                    'Max_Absolute_Error': result['max_abs_error']\n",
    "                }\n",
    "                \n",
    "                compression_results.append(compression_result)\n",
    "                all_results.append(compression_result)\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(compression_results)\n",
    "            \n",
    "            # Plotting\n",
    "            # Fine Entropy\n",
    "            axs[row, 0].plot(df['LSB_Zeroed'], df['Original_Entropy_Fine'], label='Original', marker='o')\n",
    "            axs[row, 0].plot(df['LSB_Zeroed'], df['Compressed_Entropy_Fine'], label='Compressed', marker='x')\n",
    "            axs[row, 0].set_title(f'{dist_name}: Entropy (Fine Bins)')\n",
    "            axs[row, 0].set_xlabel('LSB Zeroed')\n",
    "            axs[row, 0].set_ylabel('Entropy')\n",
    "            axs[row, 0].legend()\n",
    "\n",
    "            # Coarse Entropy\n",
    "            axs[row, 1].plot(df['LSB_Zeroed'], df['Original_Entropy_Coarse'], label='Original', marker='o')\n",
    "            axs[row, 1].plot(df['LSB_Zeroed'], df['Compressed_Entropy_Coarse'], label='Compressed', marker='x')\n",
    "            axs[row, 1].set_title(f'{dist_name}: Entropy (Coarse Bins)')\n",
    "            axs[row, 1].set_xlabel('LSB Zeroed')\n",
    "            axs[row, 1].set_ylabel('Entropy')\n",
    "            axs[row, 1].legend()\n",
    "\n",
    "            # KL Divergence\n",
    "            axs[row, 2].plot(df['LSB_Zeroed'], df['KL_Divergence_Fine'], label='Fine Bins', marker='o')\n",
    "            axs[row, 2].plot(df['LSB_Zeroed'], df['KL_Divergence_Coarse'], label='Coarse Bins', marker='x')\n",
    "            axs[row, 2].set_title(f'{dist_name}: KL Divergence')\n",
    "            axs[row, 2].set_xlabel('LSB Zeroed')\n",
    "            axs[row, 2].set_ylabel('KL Divergence')\n",
    "            axs[row, 2].legend()\n",
    "\n",
    "            # Compression Ratio and MSE\n",
    "            axs[row, 3].plot(df['LSB_Zeroed'], df['Compression_Ratio'], label='Compression Ratio', marker='o')\n",
    "            axs[row, 3].set_title(f'{dist_name}: Compression Metrics')\n",
    "            axs[row, 3].set_xlabel('LSB Zeroed')\n",
    "            axs[row, 3].set_ylabel('Compression Ratio')\n",
    "            \n",
    "            # Add a second y-axis for MSE\n",
    "            ax2 = axs[row, 3].twinx()\n",
    "            ax2.plot(df['LSB_Zeroed'], df['MSE'], label='MSE', color='red', marker='x')\n",
    "            ax2.set_ylabel('Mean Squared Error')\n",
    "            \n",
    "            # Combine legends\n",
    "            lines1, labels1 = axs[row, 3].get_legend_handles_labels()\n",
    "            lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "            axs[row, 3].legend(lines1 + lines2, labels1 + labels2, loc='best')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, 'comprehensive_compression_analysis.pdf'), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Generate comprehensive report\n",
    "        self._generate_report(results_df)\n",
    "        \n",
    "        # Save results to JSON\n",
    "        results_df.to_json(os.path.join(self.output_dir, 'compression_analysis_results.json'), orient='records')\n",
    "        \n",
    "        return results_df\n",
    "\n",
    "    def _generate_report(self, results_df):\n",
    "        \"\"\"\n",
    "        Generate a comprehensive text report\n",
    "        \n",
    "        :param results_df: DataFrame with compression and entropy results\n",
    "        \"\"\"\n",
    "        # Report path\n",
    "        report_path = os.path.join(self.output_dir, 'comprehensive_analysis_report.txt')\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"Comprehensive Compression and Entropy Analysis Report\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            # Summary for each distribution\n",
    "            for dist in results_df['Distribution'].unique():\n",
    "                dist_data = results_df[results_df['Distribution'] == dist]\n",
    "                \n",
    "                f.write(f\"Analysis for {dist} Distribution:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                \n",
    "                # Compute and write statistical insights\n",
    "                f.write(\"Statistical Insights:\\n\")\n",
    "                f.write(f\"  Average Compression Ratio: {dist_data['Compression_Ratio'].mean():.4f}\\n\")\n",
    "                f.write(f\"  Average Fine Bin Entropy Loss: {(dist_data['Original_Entropy_Fine'] - dist_data['Compressed_Entropy_Fine']).mean():.4f}\\n\")\n",
    "                f.write(f\"  Average Coarse Bin Entropy Loss: {(dist_data['Original_Entropy_Coarse'] - dist_data['Compressed_Entropy_Coarse']).mean():.4f}\\n\")\n",
    "                f.write(f\"  Average KL Divergence (Fine Bins): {dist_data['KL_Divergence_Fine'].mean():.4f}\\n\")\n",
    "                f.write(f\"  Average Mean Squared Error: {dist_data['MSE'].mean():.6f}\\n\\n\")\n",
    "        \n",
    "        print(f\"Comprehensive report generated at: {report_path}\")\n",
    "\n",
    "# Execute the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # Clear previous output\n",
    "    import shutil\n",
    "    output_dir = 'enhanced_compression_analysis'\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    \n",
    "    compressor = EnhancedFloatingPointCompressor()\n",
    "    results = compressor.analyze_compression()\n",
    "    print(\"\\nCompression and Entropy Analysis Results:\")\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae25d26-ef7c-4318-9970-1832b2627251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
